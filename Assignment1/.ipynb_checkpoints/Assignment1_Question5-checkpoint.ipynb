{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "1. Use Gutenberg and Web_text data. Find out what are the top 5 words that Shakespeare used but we do not use in currently.\n",
    "2. Take top 50 words from Shakespeare (all 3 books) and top 50 from Web_text (all the records).\n",
    "3. Remove punctuation and stop words.\n",
    "4. Remove the words we still use today, and get the unused list. Show the top 5 elements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import Gutenberg, Web_text and stopwords data\n",
    "from nltk.corpus import gutenberg \n",
    "from nltk.corpus import webtext\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import string and get the list of punctuation\n",
    "import string\n",
    "punc=string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the list of the stopwords\n",
    "stopList = stopwords.words('english')\n",
    "# print(stopList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt']\n"
     ]
    }
   ],
   "source": [
    "#find the all shakespeare txts  \n",
    "print(gutenberg.fileids()[-4:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get all the words of Shakespeare and currently\n",
    "words_shakes = gutenberg.words(gutenberg.fileids()[-4:-1])\n",
    "words_current = webtext.words(webtext.fileids())\n",
    "\n",
    "# define the function to get the clean wordList of Shakespeare and currently.\n",
    "def cleanWordFunction(List):\n",
    "    cleanWordList=[]\n",
    "    for word in List:\n",
    "        lower_word = word.lower() # change the words to lowercase\n",
    "        if lower_word not in stopList:# remove all the stop words\n",
    "            if lower_word not in punc:# remove all the punctuation\n",
    "                if lower_word.isdigit() == 0:#remove all the numbers\n",
    "                    cleanWordList.append(lower_word)             \n",
    "    return cleanWordList\n",
    "\n",
    "# generate the clean words.    \n",
    "cleanShakesWords = cleanWordFunction(words_shakes)\n",
    "cleanCurrentWords = cleanWordFunction(words_current)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17052"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get the list of words that shakespare use and not used in currently\n",
    "onlyShakes = []\n",
    "for word in cleanShakesWords:\n",
    "    if word not in cleanCurrentWords:\n",
    "        onlyShakes.append(word)\n",
    "len(onlyShakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haue 448\n",
      "vpon 162\n",
      "brutus 162\n",
      "bru 153\n",
      "hath 144\n"
     ]
    }
   ],
   "source": [
    "#define a dict named wordcountTopShakes to store the key and value of shakespare used.\n",
    "wordcountTopShakes = {}\n",
    "for word in cleanShakesWords:\n",
    "    if word not in cleanCurrentWords:\n",
    "        if word not in wordcountTopShakes:\n",
    "            wordcountTopShakes[word] = 1 # add the key and value if not in the dict\n",
    "        else:\n",
    "            wordcountTopShakes[word] += 1 # accumulate the value of the key that already exist\n",
    "wordcountTopShakes = sorted(wordcountTopShakes.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#get the most frequent 5 words\n",
    "for k,v in wordcountTopShakes[:5]:\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haue 448\n",
      "ham 337\n",
      "thou 312\n",
      "shall 300\n",
      "lord 293\n",
      "come 232\n",
      "king 231\n",
      "enter 230\n",
      "good 218\n",
      "let 217\n",
      "thy 202\n",
      "caesar 193\n",
      "vs 184\n",
      "know 176\n",
      "thee 174\n",
      "would 170\n",
      "like 162\n",
      "vpon 162\n",
      "brutus 162\n",
      "bru 153\n",
      "well 152\n",
      "hath 144\n",
      "selfe 143\n",
      "man 139\n",
      "may 138\n",
      "macb 137\n",
      "yet 136\n",
      "heere 135\n",
      "must 130\n",
      "say 130\n",
      "tis 129\n",
      "th 125\n",
      "loue 119\n",
      "speake 119\n",
      "make 119\n",
      "giue 118\n",
      "see 116\n",
      "time 115\n",
      "sir 114\n",
      "night 114\n",
      "one 112\n",
      "st 110\n",
      "cassi 107\n",
      "ile 106\n",
      "doe 103\n",
      "go 100\n",
      "hamlet 100\n",
      "men 96\n",
      "hor 95\n",
      "vp 94\n"
     ]
    }
   ],
   "source": [
    "# Take top 50 words from Shakespeare (all 3 books) \n",
    "wordcountShakes = {}\n",
    "for word in cleanShakesWords:\n",
    "    if word not in wordcountShakes:\n",
    "        wordcountShakes[word] = 1\n",
    "    else:\n",
    "        wordcountShakes[word] += 1\n",
    "wordcountShakes = sorted(wordcountShakes.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#get the most frequent 50 words\n",
    "for k,v in wordcountShakes[:50]:\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl 2956\n",
      "guy 2751\n",
      "like 1696\n",
      "... 1542\n",
      "man 1075\n",
      "know 1025\n",
      "woman 998\n",
      "yeah 895\n",
      "page 887\n",
      "firefox 879\n",
      "get 869\n",
      "new 790\n",
      "chick 714\n",
      "one 700\n",
      "oh 682\n",
      "open 679\n",
      "window 670\n",
      "good 644\n",
      "bookmarks 598\n",
      "teen 587\n",
      "well 586\n",
      "firebird 583\n",
      "cell 577\n",
      "right 576\n",
      "go 564\n",
      "work 537\n",
      "bar 536\n",
      "menu 530\n",
      "tab 529\n",
      "lady 524\n",
      "toolbar 518\n",
      "*** 498\n",
      "boy 488\n",
      "want 485\n",
      "browser 484\n",
      "think 484\n",
      "jack 483\n",
      "bookmark 482\n",
      "old 475\n",
      "really 473\n",
      "going 460\n",
      "download 442\n",
      "url 440\n",
      "back 434\n",
      "time 432\n",
      "black 422\n",
      "manager 420\n",
      "little 419\n",
      "got 409\n",
      "crash 396\n"
     ]
    }
   ],
   "source": [
    "#and top 50 from Web_text (all the records).\n",
    "wordcount_Web_text = {}\n",
    "for word in cleanCurrentWords:\n",
    "    if word not in wordcount_Web_text:\n",
    "        wordcount_Web_text[word] = 1\n",
    "    else:\n",
    "        wordcount_Web_text[word] += 1\n",
    "wordcount_Web_text = sorted(wordcount_Web_text.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#get the most frequent 50 words\n",
    "for k,v in wordcount_Web_text[:50]:\n",
    "    print(k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "haue 448\n",
      "vpon 162\n",
      "brutus 162\n",
      "bru 153\n",
      "hath 144\n"
     ]
    }
   ],
   "source": [
    "# remove the used and get the unsed named onlyShakes list before and get the most frequent 5 unused words\n",
    "unused = {}\n",
    "for word in onlyShakes:\n",
    "    if word not in unused:\n",
    "        unused[word] = 1\n",
    "    else:\n",
    "        unused[word] += 1\n",
    "unused = sorted(unused.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "#get the most frequent 5 unsed words\n",
    "for k,v in unused[:5]:\n",
    "    print(k,v)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
